{"version":3,"file":"44664.ee5ed550.iframe.bundle.js","mappings":";AAmFA;AACA;;;AAGA;;;;AAkBA;AACA;AACA;AACA;;;;AAyBA;;;;;AAKA;AACA;AACA;AACA;;AAEA","sources":["webpack://@posthog/storybook/../../frontend/src/scenes/hog-functions/logs/logsViewerLogic.tsx"],"sourcesContent":["import {\n    actions,\n    afterMount,\n    beforeUnmount,\n    kea,\n    key,\n    listeners,\n    path,\n    props,\n    propsChanged,\n    reducers,\n    selectors,\n} from 'kea'\nimport { loaders } from 'kea-loaders'\nimport { actionToUrl, router, urlToAction } from 'kea-router'\n\nimport { lemonToast } from '@posthog/lemon-ui'\n\nimport api from 'lib/api'\nimport { Dayjs, dayjs } from 'lib/dayjs'\nimport { teamLogic } from 'scenes/teamLogic'\n\nimport { HogQLQueryString, hogql } from '~/queries/utils'\nimport { LogEntryLevel } from '~/types'\n\nimport type { logsViewerLogicType } from './logsViewerLogicType'\n\nexport const ALL_LOG_LEVELS: LogEntryLevel[] = ['DEBUG', 'LOG', 'INFO', 'WARNING', 'ERROR']\nexport const DEFAULT_LOG_LEVELS: LogEntryLevel[] = ['DEBUG', 'LOG', 'INFO', 'WARNING', 'ERROR']\nexport const POLLING_INTERVAL = 5000\nexport const LOG_VIEWER_LIMIT = 100\n\nexport type LogsViewerLogicProps = {\n    logicKey?: string\n    sourceType: 'hog_function' | 'hog_flow' | 'batch_export'\n    sourceId: string\n    groupByInstanceId?: boolean\n    searchGroups?: string[]\n}\n\nexport type LogsViewerFilters = {\n    levels: LogEntryLevel[]\n    search: string\n    date_from?: string\n    date_to?: string\n}\n\nexport type LogEntry = {\n    message: string\n    instanceId: string\n    level: LogEntryLevel\n    timestamp: Dayjs\n}\n\nexport type GroupedLogEntry = {\n    instanceId: string\n    maxTimestamp: Dayjs\n    minTimestamp: Dayjs\n    logLevel: LogEntryLevel\n    entries: LogEntry[]\n}\n\nexport type LogEntryParams = {\n    sourceType: 'hog_function' | 'hog_flow'\n    sourceId: string\n    levels: LogEntryLevel[]\n    searchGroups: string[]\n    dateFrom?: string\n    dateTo?: string\n    order: 'ASC' | 'DESC'\n}\n\nconst toKey = (log: LogEntry): string => {\n    return `${log.instanceId}-${log.level}-${log.timestamp.toISOString()}`\n}\n\nconst toAbsoluteClickhouseTimestamp = (timestamp: Dayjs): string => {\n    // TRICKY: CH query is timezone aware so we dont send iso\n    return timestamp.format('YYYY-MM-DD HH:mm:ss.SSS')\n}\n\nconst buildBoundaryFilters = (request: LogEntryParams): string => {\n    return hogql`\n        AND log_source = ${request.sourceType}\n        AND log_source_id = ${request.sourceId}\n        AND timestamp > {filters.dateRange.from}\n        AND timestamp < {filters.dateRange.to}\n    `\n}\n\nconst buildSearchFilters = ({ searchGroups, levels }: LogEntryParams): string => {\n    let query = hogql`\\nAND lower(level) IN (${hogql.raw(levels.map((level) => `'${level.toLowerCase()}'`).join(','))})`\n\n    searchGroups.forEach((search) => {\n        query = (query + hogql`\\nAND message ILIKE '%${hogql.raw(search)}%'`) as HogQLQueryString\n    })\n\n    return query\n}\n\nconst loadLogs = async (request: LogEntryParams): Promise<LogEntry[]> => {\n    const query = hogql`\n        SELECT instance_id, timestamp, level, message\n        FROM log_entries\n        WHERE 1=1\n        ${hogql.raw(buildBoundaryFilters(request))}\n        ${hogql.raw(buildSearchFilters(request))}\n        ORDER BY timestamp ${hogql.raw(request.order)}\n        LIMIT ${LOG_VIEWER_LIMIT}`\n\n    const response = await api.queryHogQL(query, {\n        refresh: 'force_blocking',\n        filtersOverride: {\n            date_from: request.dateFrom ?? '-7d',\n            date_to: request.dateTo,\n        },\n    })\n\n    return response.results.map(\n        (result): LogEntry => ({\n            instanceId: result[0],\n            timestamp: dayjs(result[1]),\n            level: result[2].toUpperCase(),\n            message: result[3],\n        })\n    )\n}\n\nconst loadGroupedLogs = async (request: LogEntryParams): Promise<LogEntry[]> => {\n    const query = hogql`\n        SELECT instance_id, timestamp, level, message\n        FROM log_entries\n        WHERE 1=1 \n        ${hogql.raw(buildBoundaryFilters(request))}\n        AND instance_id in (\n            SELECT DISTINCT instance_id\n            FROM log_entries\n            WHERE 1=1\n            ${hogql.raw(buildBoundaryFilters(request))}\n            ${hogql.raw(buildSearchFilters(request))}\n            ORDER BY timestamp ${hogql.raw(request.order)}\n            LIMIT ${LOG_VIEWER_LIMIT}\n        )\n        ORDER BY timestamp DESC`\n\n    const response = await api.queryHogQL(query, {\n        refresh: 'force_blocking',\n        filtersOverride: {\n            date_from: request.dateFrom ?? '-7d',\n            date_to: request.dateTo,\n        },\n    })\n\n    return response.results.map(\n        (result): LogEntry => ({\n            instanceId: result[0],\n            timestamp: dayjs(result[1]),\n            level: result[2].toUpperCase(),\n            message: result[3],\n        })\n    )\n}\n\nconst groupLogs = (logs: LogEntry[]): GroupedLogEntry[] => {\n    const byId: Record<string, GroupedLogEntry> = {}\n    const dedupeCache = new Set<string>()\n\n    for (const log of logs) {\n        const key = toKey(log)\n        if (dedupeCache.has(key)) {\n            continue\n        }\n        dedupeCache.add(key)\n        const group = byId[log.instanceId] ?? {\n            instanceId: log.instanceId,\n            maxTimestamp: log.timestamp,\n            minTimestamp: log.timestamp,\n            logLevel: log.level,\n            entries: [],\n        }\n        byId[log.instanceId] = group\n        group.entries.push(log)\n        group.maxTimestamp = log.timestamp.isAfter(group.maxTimestamp) ? log.timestamp : group.maxTimestamp\n        group.minTimestamp = log.timestamp.isBefore(group.minTimestamp) ? log.timestamp : group.minTimestamp\n        if (ALL_LOG_LEVELS.indexOf(log.level) > ALL_LOG_LEVELS.indexOf(group.logLevel)) {\n            group.logLevel = log.level\n        }\n    }\n\n    return Object.values(byId).map((group) => ({\n        ...group,\n        entries: group.entries.sort((a, b) => a.timestamp.diff(b.timestamp)),\n    }))\n}\n\nexport const logsViewerLogic = kea<logsViewerLogicType>([\n    path((key) => ['scenes', 'pipeline', 'hogfunctions', 'logs', 'logsViewerLogic', key]),\n    props({} as LogsViewerLogicProps), // TODO: Remove `stage` from props, it isn't needed here for anything\n    key(({ sourceType, sourceId, logicKey }) => logicKey || `${sourceType}:${sourceId}`),\n    actions({\n        setFilters: (filters: Partial<LogsViewerFilters>) => ({ filters }),\n        addLogGroups: (logGroups: GroupedLogEntry[]) => ({ logGroups }),\n        clearHiddenLogs: true,\n        markLogsEnd: true,\n        revealHiddenLogs: true,\n        setRowExpanded: (instanceId: string, expanded: boolean) => ({ instanceId, expanded }),\n        scheduleLoadNewerLogs: true,\n        loadLogs: true,\n        loadNewerLogs: true,\n        loadOlderLogs: true,\n        clearLogs: true,\n        loadGroupedLogs: true,\n        loadUngroupedLogs: true,\n        setIsGrouped: (isGrouped: boolean) => ({ isGrouped }),\n    }),\n    reducers(({ props }) => ({\n        isGrouped: [\n            props.groupByInstanceId ?? true,\n            {\n                setIsGrouped: (_, { isGrouped }) => isGrouped,\n            },\n        ],\n        filters: [\n            {\n                search: '',\n                levels: DEFAULT_LOG_LEVELS,\n                date_from: '-7d',\n                date_to: undefined,\n            } as LogsViewerFilters,\n            {\n                setFilters: (state, { filters }) => ({\n                    ...state,\n                    ...filters,\n                }),\n            },\n        ],\n        isThereMoreToLoad: [\n            true,\n            {\n                markLogsEnd: () => false,\n                loadLogs: () => true,\n            },\n        ],\n        expandedRows: [\n            {} as Record<string, boolean>,\n            {\n                setRowExpanded: (state, { instanceId, expanded }) => ({\n                    ...state,\n                    [instanceId]: expanded,\n                }),\n            },\n        ],\n\n        unGroupedLogs: [\n            [] as LogEntry[],\n            {\n                clearLogs: () => [],\n            },\n        ],\n        groupedLogs: [\n            [] as GroupedLogEntry[],\n            {\n                clearLogs: () => [],\n            },\n        ],\n    })),\n    loaders(({ values, actions }) => ({\n        unGroupedLogs: [\n            [] as LogEntry[],\n            {\n                loadUngroupedLogs: async (_, breakpoint) => {\n                    await breakpoint(10)\n                    actions.clearHiddenLogs()\n                    const results = await loadLogs(values.logEntryParams)\n                    await breakpoint(10)\n                    return results\n                },\n                loadMoreUngroupedLogs: async () => {\n                    if (!values.oldestLogTimestamp) {\n                        return values.unGroupedLogs\n                    }\n                    const logParams: LogEntryParams = {\n                        ...values.logEntryParams,\n                        dateTo: toAbsoluteClickhouseTimestamp(values.oldestLogTimestamp),\n                    }\n\n                    const results = await loadLogs(logParams)\n\n                    if (!results.length) {\n                        actions.markLogsEnd()\n                    }\n\n                    const newLogs = results.filter((log) => !values.allLogEntryKeys.has(toKey(log)))\n                    return [...newLogs, ...values.unGroupedLogs].sort((a, b) => b.timestamp.diff(a.timestamp))\n                },\n            },\n        ],\n        groupedLogs: [\n            [] as GroupedLogEntry[],\n            {\n                loadGroupedLogs: async (_, breakpoint) => {\n                    await breakpoint(10)\n\n                    actions.clearHiddenLogs()\n                    const results = await loadGroupedLogs(values.logEntryParams).catch((e) => {\n                        lemonToast.error('Error loading logs ' + e.message)\n                        throw e\n                    })\n                    await breakpoint(10)\n\n                    return groupLogs(results)\n                },\n                loadMoreGroupedLogs: async () => {\n                    if (!values.oldestLogTimestamp) {\n                        return values.groupedLogs\n                    }\n                    const logParams: LogEntryParams = {\n                        ...values.logEntryParams,\n                        dateTo: toAbsoluteClickhouseTimestamp(values.oldestLogTimestamp),\n                    }\n\n                    const results = await loadGroupedLogs(logParams)\n\n                    if (!results.length) {\n                        actions.markLogsEnd()\n                    }\n                    return groupLogs([...results, ...values.groupedLogs.flatMap((group) => group.entries)])\n                },\n\n                addLogGroups: ({ logGroups }) => {\n                    return groupLogs([\n                        ...logGroups.flatMap((group) => group.entries),\n                        ...values.groupedLogs.flatMap((group) => group.entries),\n                    ])\n                },\n            },\n        ],\n\n        hiddenLogs: [\n            [] as LogEntry[],\n            {\n                loadNewerLogs: async (_, breakpoint) => {\n                    await breakpoint(10)\n\n                    // We load all logs groups that have a timestamp after the newest log timestamp\n                    // For ones we already have we just replace them, otherwise we add them to the \"hidden\" logs list\n                    if (!values.newestLogTimestamp) {\n                        return values.hiddenLogs\n                    }\n\n                    const logParams: LogEntryParams = {\n                        ...values.logEntryParams,\n                        dateFrom: toAbsoluteClickhouseTimestamp(values.newestLogTimestamp),\n                        order: 'ASC',\n                    }\n\n                    let newLogs: LogEntry[] = []\n\n                    if (values.isGrouped) {\n                        const results = await loadGroupedLogs(logParams)\n\n                        await breakpoint(10)\n\n                        const newLogs: LogEntry[] = []\n                        const newLogsToImmediateAdd: LogEntry[] = []\n                        const existingLogIds = values.groupedLogs.map((log) => log.instanceId)\n\n                        if (values.logsLoading) {\n                            // TRICKY: Something changed whilst we were doing this query - we don't want to mess with things\n                            // so we just exit\n                            return values.hiddenLogs\n                        }\n\n                        for (const log of results) {\n                            if (existingLogIds.includes(log.instanceId)) {\n                                // If we already have this log group showing then we can just update it\n                                newLogsToImmediateAdd.push(log)\n                            } else {\n                                // Otherwise we add it to the list of hidden logs\n                                newLogs.push(log)\n                            }\n                        }\n\n                        if (newLogsToImmediateAdd.length) {\n                            // Update the existing logs with the new data\n                            actions.loadGroupedLogsSuccess(\n                                groupLogs([\n                                    ...newLogsToImmediateAdd,\n                                    ...values.groupedLogs.flatMap((group) => group.entries),\n                                ])\n                            )\n                        }\n                    } else {\n                        const results = await loadLogs(logParams)\n                        await breakpoint(10)\n                        newLogs = results\n                    }\n\n                    actions.scheduleLoadNewerLogs()\n\n                    // Filter out any duplicates as the time ranges are never perfectly accurate\n                    newLogs = newLogs.filter((log) => !values.allLogEntryKeys.has(toKey(log)))\n\n                    return [...newLogs, ...values.hiddenLogs]\n                },\n                clearHiddenLogs: () => [],\n            },\n        ],\n    })),\n    selectors(() => ({\n        logsLoading: [\n            (s) => [s.groupedLogsLoading, s.unGroupedLogsLoading],\n            (groupedLogsLoading, unGroupedLogsLoading): boolean => {\n                return groupedLogsLoading || unGroupedLogsLoading\n            },\n        ],\n        logEntryParams: [\n            (s) => [(_, p) => p, s.filters],\n            (props, filters): LogEntryParams => {\n                const searchGroups = [filters.search, ...(props.searchGroups || [])].filter((x) => !!x) as string[]\n                return {\n                    levels: filters.levels,\n                    searchGroups: searchGroups,\n                    sourceType: props.sourceType,\n                    sourceId: props.sourceId,\n                    dateFrom: filters.date_from,\n                    dateTo: filters.date_to,\n                    order: 'DESC',\n                }\n            },\n        ],\n\n        allLogEntries: [\n            (s) => [s.groupedLogs, s.unGroupedLogs, s.hiddenLogs],\n            (groupedLogs, unGroupedLogs, hiddenLogs): LogEntry[] => {\n                return [...groupedLogs.flatMap((log) => log.entries), ...unGroupedLogs, ...hiddenLogs]\n            },\n        ],\n\n        allLogEntryKeys: [\n            (s) => [s.allLogEntries],\n            (allLogEntries): Set<string> => {\n                return new Set(allLogEntries.map(toKey))\n            },\n        ],\n\n        newestLogTimestamp: [\n            (s) => [s.allLogEntries],\n            (allLogEntries): Dayjs | null => {\n                const item = allLogEntries.reduce(\n                    (max, log) => {\n                        if (!max) {\n                            return log.timestamp\n                        }\n                        return log.timestamp.isAfter(max) ? log.timestamp : max\n                    },\n                    null as Dayjs | null\n                )\n\n                return item ? item.tz(teamLogic.findMounted()?.values.currentTeam?.timezone) : null\n            },\n        ],\n\n        oldestLogTimestamp: [\n            (s) => [s.allLogEntries],\n            (allLogEntries): Dayjs | null => {\n                return allLogEntries.reduce(\n                    (min, log) => {\n                        if (!min) {\n                            return log.timestamp\n                        }\n                        return log.timestamp.isBefore(min) ? log.timestamp : min\n                    },\n                    null as Dayjs | null\n                )\n            },\n        ],\n    })),\n    propsChanged(({ props, actions }, oldProps) => {\n        if (props.groupByInstanceId !== oldProps.groupByInstanceId) {\n            actions.setIsGrouped(props.groupByInstanceId ?? true)\n        }\n    }),\n    listeners(({ actions, cache, values }) => ({\n        loadLogs: () => {\n            clearTimeout(cache.pollingTimeout)\n\n            if (values.isGrouped) {\n                actions.loadGroupedLogs()\n            } else {\n                actions.loadUngroupedLogs()\n            }\n        },\n        loadOlderLogs: () => {\n            if (values.isGrouped) {\n                actions.loadMoreGroupedLogs()\n            } else {\n                actions.loadMoreUngroupedLogs()\n            }\n        },\n        setFilters: async ({ filters }, breakpoint) => {\n            await breakpoint(filters.search ? 500 : 10) // Longer debounce when typing in the search field\n            actions.loadLogs()\n        },\n        setIsGrouped: async () => {\n            actions.clearLogs()\n            actions.loadLogs()\n        },\n        loadGroupedLogsSuccess: () => actions.scheduleLoadNewerLogs(),\n        loadUngroupedLogsSuccess: () => actions.scheduleLoadNewerLogs(),\n        scheduleLoadNewerLogs: () => {\n            clearTimeout(cache.pollingTimeout)\n            cache.pollingTimeout = setTimeout(() => actions.loadNewerLogs(), POLLING_INTERVAL)\n        },\n\n        revealHiddenLogs: () => {\n            if (!values.hiddenLogs.length) {\n                return\n            }\n\n            if (values.isGrouped) {\n                actions.loadMoreGroupedLogsSuccess(\n                    groupLogs([...values.hiddenLogs, ...values.groupedLogs.flatMap((group) => group.entries)])\n                )\n            } else {\n                actions.loadMoreUngroupedLogsSuccess(\n                    [...values.unGroupedLogs, ...values.hiddenLogs].sort((a, b) => b.timestamp.diff(a.timestamp))\n                )\n            }\n\n            actions.clearHiddenLogs()\n        },\n    })),\n    afterMount(({ actions }) => {\n        actions.loadLogs()\n    }),\n    beforeUnmount(({ cache }) => {\n        clearInterval(cache.pollingTimeout)\n    }),\n    actionToUrl(({ values }) => {\n        const syncProperties = (\n            properties: Record<string, any>\n        ): [string, Record<string, any>, Record<string, any>] => {\n            const newSearch = { ...router.values.searchParams, ...properties }\n            Object.keys(properties).forEach((key) => {\n                if (properties[key] === null || properties[key] === undefined) {\n                    delete newSearch[key]\n                }\n            })\n            return [router.values.location.pathname, newSearch, router.values.hashParams]\n        }\n\n        return {\n            setFilters: ({ filters }) => syncProperties(filters),\n            setIsGrouped: () => syncProperties({ grouped: values.isGrouped }),\n        }\n    }),\n    urlToAction(({ actions, values }) => {\n        const reactToTabChange = (_: any, search: Record<string, any>): void => {\n            Object.keys(search).forEach((key) => {\n                if (key in values.filters && search[key] !== values.filters[key as keyof LogsViewerFilters]) {\n                    actions.setFilters({ [key]: search[key] })\n                }\n            })\n\n            if (typeof search.grouped === 'boolean' && search.grouped !== values.isGrouped) {\n                actions.setIsGrouped(search.grouped)\n            }\n        }\n\n        return {\n            '*': reactToTabChange,\n        }\n    }),\n])\n"],"names":[],"sourceRoot":""}